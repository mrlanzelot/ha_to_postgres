# Mini Zenseact Pipeline â€“ Home Assistant â†’ Event-Based Data Platform

This project is a personal exploration of how to build a modern, event-driven data pipeline inspired by the data infrastructure patterns used in advanced automotive data platforms.  
The system ingests telemetry from **Home Assistant**, publishes changes as events, processes them, stores metrics in **PostgreSQL**, and makes them available for **Grafana analytics** and later for **Kafka-based streaming**, **OpenLineage tracking**, and **DataHub metadata registry**.

---

## ğŸš€ Goals

- Replace legacy **cron-based ingestion** with **real-time events**
- Introduce **Kafka (KRaft)** for scalable event streaming
- Use **Airflow 3 event-based DAG triggers**
- Add **OpenTelemetry** for distributed tracing + structured logging
- Track metadata and lineage using **OpenLineage**
- Register datasets and pipelines into **DataHub**
- Provide a small-scale but modern version of a **production-grade pipeline**

---

## ğŸ—ï¸ Current Architecture (Phase 1)

Home Assistant
â”‚
â–¼
MQTT (Mosquitto)
â”‚
â–¼
ha_ingest.py â†’ JSON event
â”‚
â–¼
PostgreSQL (table: ha_sensor_state)
â”‚
â–¼
Grafana dashboards

---

## ğŸ› ï¸ Project Structure

ha_to_postgres/
â”‚
â”œâ”€â”€ .env
â”œâ”€â”€ config.yaml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Makefile
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ ha_ingest.py # MQTT â†’ Postgres ingestion
â”‚ â”œâ”€â”€ pipeline.py # Legacy ingestion (cron-based)
â”‚ â”œâ”€â”€ config_loader.py # YAML config loader
â”‚ â”œâ”€â”€ logging_config.py # OTEL logging + Python logging
â”‚ â”œâ”€â”€ ha_client.py # Home Assistant REST client
â”‚ â”œâ”€â”€ db.py # Postgres connection pool + inserts
â”‚ â”œâ”€â”€ models.py # Pydantic models for validation
â”‚ â””â”€â”€ utils.py # Shared helpers
â”‚
â””â”€â”€ docs/
â”œâ”€â”€ architecture.png
â”œâ”€â”€ lineage_overview.md
â””â”€â”€ roadmap.md

---

## ğŸ”§ Setup

### 1. Clone the repository
```bash
git clone https://github.com/mrlanzelot/ha_to_postgres.git
cd ha_to_postgres

2. Create virtual environment
bash
Kopiera kod
python3 -m venv venv
source venv/bin/activate

3. Install dependencies
bash
pip install -r requirements.txt


4. Configure environment

Create .env:

HA_BASE_URL=http://192.168.68.74:8123
HA_TOKEN=your_long_lived_token_here
POSTGRES_HOST=localhost
POSTGRES_USER=postgres
POSTGRES_PASSWORD=<postgres
POSTGRES_DB=home
MQTT_HOST=192.168.68.72

5. Configure sensors (config.yaml)

sensors:
  - entity_id: sensor.smhi_temperature
    value_attribute: state
    unit_attribute: unit_of_measurement

  - entity_id: sensor.last_perific_last_current_l1
    value_attribute: state
    unit_attribute: unit_of_measurement
â–¶ Run the ingestion pipeline (event-based)
bash
make run
Starts:

MQTT listener

JSON decoding

Validation (Pydantic)

DB insertion

Error handling

ğŸ—„ Database Schema
sql
CREATE TABLE sensor_raw (
    id SERIAL PRIMARY KEY,
    entity_id TEXT NOT NULL,
    metric TEXT NOT NULL,      -- state, temperature, humidity, power, etc.    
    value DOUBLE PRECISION,
    unit TEXTtime, 
    ts TIMESTAMPTZ NOT NULL,
);
ğŸ“ˆ Grafana Integration
Once PostgreSQL is populated, Grafana can visualize:

Real-time sensor telemetry

EV charger load & 3-phase distribution

Weather patterns

Energy consumption

ğŸ›¤ Roadmap
âœ” Phase 1 (Done)
Local ingestion from MQTT

Postgres storage

YAML config

Logging 

GitHub repo creation

ğŸ”œ Phase 2 â€” Event-Driven Pipeline
Kafka with KRaft mode

Kafka producers & consumers

Replace MQTT â†’ Postgres with:

nginx
Kopiera kod
HA â†’ MQTT â†’ Kafka â†’ Kafka Consumer â†’ Postgres
ğŸ”œ Phase 3 â€” Airflow 3 + OpenLineage
Event-triggered DAGs

Lineage tracking via OpenLineage

Dataset registration

ğŸ”œ Phase 4 â€” DataHub Integration
Automatic dataset and lineage publishing

Graph view of full HA-to-Grafana flow

ğŸ”œ Phase 5 â€” Analytics layer
Aggregated tables

Materialized views

Time-series optimizations

ğŸ§ª Tests (future)
Unit tests for ha_ingest

Integration tests via docker-compose

Kafka stream tests

ğŸ“« Contact / Author
Martin LanzÃ©n
Home automation, data engineering, and modern pipeline enthusiast.
